# GBDT调参

## 1.有关单个树的参数

![](https://www.analyticsvidhya.com/wp-content/uploads/2016/02/tree-infographic.png)

**min_samples_split**: 允许分裂的结点所包含的最小样本数，为了控制过拟合，通过cv确定具体值。

**min_samples_leaf**：一个叶子中至少要包含的样本数，为了控制过拟合,在不平衡分类中要设置的小。

**min_weight_fraction_leaf**：一个叶子包含样本数占总样本数的最小权重，与min_samples_leaf类似（调参时二选一），只不过用分数表示。

**max_depth**：树的最大深度，为了控制过拟合（太深），通过cv确定具体值。

**max_leaf_nodes**：最大叶子数量（本质上与max_depth一样）

**max_features**：选择最佳划分时，考虑的最大特征数。一般选取总特征数的平方根，或30%~40%



## 2.有关提升过程的参数

**learning_rate**：学习率（0<x<=1），决定了在集成时候每棵树的影响力。通常选取较低的值，这样fan'hua'xing泛化性强，但需要训练更多的树。

**n_estimators**：树的数量。用cv确定值

**subsample**：为每棵树选择的样本大小（0~1）。通常为0.8



## 3.其他参数

**loss**：损失函数。通常使用默认的即可

**init**：初始化的输出结果

**random_state**：随机数种子（以便每次生成相同的随机数）。这对调参很重要，因为如果不设置，每次的结果都不同。

**verbose**：当训练模型过程中输出的结果样式（0：不输出；1：以一定时间间隔输出；>1:输出所有树）

**warm_start**：热启动

**presort **：是否预排序，以加速分割



